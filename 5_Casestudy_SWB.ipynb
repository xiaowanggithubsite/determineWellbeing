{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wGo5elhzCHPT",
   "metadata": {
    "id": "wGo5elhzCHPT"
   },
   "source": [
    "# input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5329c894",
   "metadata": {
    "executionInfo": {
     "elapsed": 2751,
     "status": "ok",
     "timestamp": 1706106724473,
     "user": {
      "displayName": "Xiao Wang",
      "userId": "01292932993361768036"
     },
     "user_tz": -60
    },
    "id": "5329c894"
   },
   "outputs": [],
   "source": [
    "#Import statements\n",
    "import random\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV #built in class to provide tuning\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from numpy import arange\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import preprocessing\n",
    "random.seed(1) #set a seed for reproducable result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7tYHgYU1lf6Y",
   "metadata": {
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1706107167648,
     "user": {
      "displayName": "Xiao Wang",
      "userId": "01292932993361768036"
     },
     "user_tz": -60
    },
    "id": "7tYHgYU1lf6Y"
   },
   "outputs": [],
   "source": [
    "def combine_embedding_with_table(embedding_name,modelling_variable):\n",
    "\n",
    "    \"\"\"\n",
    "    Combine  embedding  with a basetable and performs some data preprocessing.\n",
    "\n",
    "    Args:\n",
    "    - embedding_name (str): the name of the embedding ('glove', 'elmo', 'berttwitter', 'sentencebert', 'universal').\n",
    "    - modelling_variable (str): the name of  ('SWB', 'Positive_affect', 'Negative_affect').\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: The combined embedding and basetable\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    basetable = pd.read_csv(\"./data/ModelData.csv\")\n",
    "    try:\n",
    "        # Construct file path of embedding\n",
    "        filename = f\"./data/{embedding_name}.csv\"\n",
    "\n",
    "        # Read the CSV file into a DataFrame\n",
    "        emb_table = pd.read_csv(filename)\n",
    "\n",
    "        # Concatenate the basetable and the embedding\n",
    "        basetable = pd.concat([basetable, emb_table], axis=1)\n",
    "\n",
    "        # List of column names to delet\n",
    "       # List of column names to delet\n",
    "        columns_to_delete = ['created_at', 'full_text',\n",
    "                     'Attentive','Alert','Determined','Inspired','Active',\n",
    "                     'Hostile','Ashamed','Upset','Afraid','Nervous',\n",
    "                     'OriginalText','clean_text','neu' ]\n",
    "        basetable = basetable.drop(columns=columns_to_delete)\n",
    "\n",
    "        # List of column names to delete based on modelling_variable\n",
    "        if modelling_variable == 'SWB':\n",
    "            columns_to_delete = ['Positive_affect', 'Negative_affect']\n",
    "        elif modelling_variable == 'Positive_affect':\n",
    "            columns_to_delete = ['SWB', 'Negative_affect']\n",
    "        elif modelling_variable == 'Negative_affect':\n",
    "            columns_to_delete = ['SWB', 'Positive_affect']\n",
    "        else:\n",
    "            columns_to_delete = []\n",
    "        basetable = basetable.drop(columns=columns_to_delete)\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"Combined {embedding_name} with basetable.\")\n",
    "        print(f\"Dropped columns: {columns_to_delete}\")\n",
    "        print(\"=\" * 40)\n",
    "        print(f\"This code is used to build a model of {modelling_variable} using {embedding_name}\")\n",
    "\n",
    "        return basetable\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{embedding_name}' not found.\")\n",
    "        return basetable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Gwom6K9oj8XP",
   "metadata": {
    "id": "Gwom6K9oj8XP"
   },
   "source": [
    "# SWB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J4xNjasooppG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8104,
     "status": "ok",
     "timestamp": 1706107180464,
     "user": {
      "displayName": "Xiao Wang",
      "userId": "01292932993361768036"
     },
     "user_tz": -60
    },
    "id": "J4xNjasooppG",
    "outputId": "e21f6450-1fc8-4331-cac8-7e06e02d4bbd"
   },
   "outputs": [],
   "source": [
    "##here input two , one is embedding name, another is the dependent variable to build a model\n",
    "#('glove', '1024elmo', 'berttwitter', 'sentencebert', 'universal')\n",
    "#('SWB', 'Positive_affect', 'Negative_affect')\n",
    "basetable=combine_embedding_with_table('openai','SWB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1AqQuj_uWMC1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1706107192808,
     "user": {
      "displayName": "Xiao Wang",
      "userId": "01292932993361768036"
     },
     "user_tz": -60
    },
    "id": "1AqQuj_uWMC1",
    "outputId": "5b3ad344-4454-4e43-9898-e895b5a43084"
   },
   "outputs": [],
   "source": [
    "basetable.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nM4kPcmp1Kzy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "executionInfo": {
     "elapsed": 2108,
     "status": "ok",
     "timestamp": 1706107197618,
     "user": {
      "displayName": "Xiao Wang",
      "userId": "01292932993361768036"
     },
     "user_tz": -60
    },
    "id": "nM4kPcmp1Kzy",
    "outputId": "fd8dcfd9-78d3-4a31-baea-0636a89c9280"
   },
   "outputs": [],
   "source": [
    "basetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FOB_rgM-yg81",
   "metadata": {
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1706107203031,
     "user": {
      "displayName": "Xiao Wang",
      "userId": "01292932993361768036"
     },
     "user_tz": -60
    },
    "id": "FOB_rgM-yg81"
   },
   "outputs": [],
   "source": [
    "#now create date\n",
    "covid_start = pd.to_datetime('2020-01-30', utc = True)\n",
    "basetable['created_at'] = covid_start + pd.to_timedelta(basetable['days_since_COVID19'], unit='D')\n",
    "basetable['created_at'] = basetable['created_at'].dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X0oJqKiuz0Bh",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1706107205199,
     "user": {
      "displayName": "Xiao Wang",
      "userId": "01292932993361768036"
     },
     "user_tz": -60
    },
    "id": "X0oJqKiuz0Bh"
   },
   "outputs": [],
   "source": [
    "basetable = basetable.sort_values(by='created_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7W8jIooL0D6L",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "executionInfo": {
     "elapsed": 1855,
     "status": "ok",
     "timestamp": 1706107208893,
     "user": {
      "displayName": "Xiao Wang",
      "userId": "01292932993361768036"
     },
     "user_tz": -60
    },
    "id": "7W8jIooL0D6L",
    "outputId": "f73d12a8-1656-4a26-8746-892fadde41fe"
   },
   "outputs": [],
   "source": [
    "basetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tUHV5R6qVPUJ",
   "metadata": {
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1706107215458,
     "user": {
      "displayName": "Xiao Wang",
      "userId": "01292932993361768036"
     },
     "user_tz": -60
    },
    "id": "tUHV5R6qVPUJ"
   },
   "outputs": [],
   "source": [
    "X = basetable.drop(['SWB','created_at','neg','pos',\t'compound',\t'TextBlob_score','days_since_COVID19'], axis = 1)\n",
    "y = basetable['SWB']\n",
    "\n",
    "X[\"is_quote_status\"] = X[\"is_quote_status\"].astype(int)\n",
    "X[\"is_reply\"] = X[\"is_reply\"].astype(int)\n",
    "X[\"possibly_sensitive\"] = X[\"possibly_sensitive\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YDmZ0KowzpzK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "executionInfo": {
     "elapsed": 1700,
     "status": "ok",
     "timestamp": 1706107219300,
     "user": {
      "displayName": "Xiao Wang",
      "userId": "01292932993361768036"
     },
     "user_tz": -60
    },
    "id": "YDmZ0KowzpzK",
    "outputId": "86c5cfba-7da9-499d-9afc-ddd8f3bcf570"
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-9DzzTn3D9pb",
   "metadata": {
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1706107225478,
     "user": {
      "displayName": "Xiao Wang",
      "userId": "01292932993361768036"
     },
     "user_tz": -60
    },
    "id": "-9DzzTn3D9pb"
   },
   "outputs": [],
   "source": [
    "# Define the ratio for the split\n",
    "split_ratio = 0.7  # 70% for training, 30% for testing\n",
    "\n",
    "# Calculate the index to split the data\n",
    "split_index = int(len(X) * split_ratio)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train = X[:split_index]\n",
    "y_train = y[:split_index]\n",
    "X_test = X[split_index:]\n",
    "y_test = y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DlrNFG4kD9tj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "executionInfo": {
     "elapsed": 2470,
     "status": "ok",
     "timestamp": 1706107230158,
     "user": {
      "displayName": "Xiao Wang",
      "userId": "01292932993361768036"
     },
     "user_tz": -60
    },
    "id": "DlrNFG4kD9tj",
    "outputId": "4c82196c-08c7-4765-b715-e54f4826a14b"
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dBa1PBXvlhRH",
   "metadata": {
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1706107233797,
     "user": {
      "displayName": "Xiao Wang",
      "userId": "01292932993361768036"
     },
     "user_tz": -60
    },
    "id": "dBa1PBXvlhRH"
   },
   "outputs": [],
   "source": [
    "##here we use NN+openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dB6ygw_GlhUl",
   "metadata": {
    "executionInfo": {
     "elapsed": 784,
     "status": "ok",
     "timestamp": 1706107243101,
     "user": {
      "displayName": "Xiao Wang",
      "userId": "01292932993361768036"
     },
     "user_tz": -60
    },
    "id": "dB6ygw_GlhUl"
   },
   "outputs": [],
   "source": [
    "model =  MLPRegressor(random_state=1)\n",
    "\n",
    "# defining parameter range\n",
    "param_grid = {'hidden_layer_sizes': [2,4,6,8,10,12,14,16,18,20],\n",
    "              'batch_size':[32],\n",
    "             'alpha': [10**(-4), 10**(-3.5), 10**(-3), 10**(-2.5), 10**(-2), 10**(-1.5), 10**(-1), 10**(-0.5), 0]}\n",
    "\n",
    "\n",
    "\n",
    "#sclaing part of features\n",
    "scale_columns=['retweet_count','favorite_count',\n",
    "                   'hour','url_count','mentions_count','questionmark_count',\n",
    "                   'exclamationmark_count','points_count','uppercase_ratio',\n",
    "                   'hashtag_count']\n",
    "\n",
    "#select the columns to scale\n",
    "X_train_scale = X_train[scale_columns]\n",
    "X_test_scale = X_test[scale_columns]\n",
    "\n",
    "X_train_unscale = X_train.drop(columns=scale_columns)\n",
    "X_test_unscale = X_test.drop(columns=scale_columns)\n",
    "\n",
    "scaler = StandardScaler().fit(X_train_scale)\n",
    "X_train_transformed = pd.DataFrame(scaler.transform(X_train_scale), columns=scale_columns)\n",
    "X_test_transformed = pd.DataFrame(scaler.transform(X_test_scale), columns=scale_columns)\n",
    "\n",
    "\n",
    "# Reset the indexes of both DataFrames\n",
    "X_train_unscale.reset_index(drop=True, inplace=True)\n",
    "X_train_transformed.reset_index(drop=True, inplace=True)\n",
    "X_test_unscale.reset_index(drop=True, inplace=True)\n",
    "X_test_transformed.reset_index(drop=True, inplace=True)\n",
    "# Concatenate the DataFrames together\n",
    "X_train = pd.concat([X_train_transformed,X_train_unscale,], axis=1)\n",
    "X_test = pd.concat([X_test_transformed,X_test_unscale], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kVTdhymJlhXP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kVTdhymJlhXP",
    "outputId": "f55471bc-fc73-4eeb-fcb4-02c1969dc06b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "print('Config: %s' % grid_search.best_params_)\n",
    "\n",
    "final_model = best_model.fit(X_train, y_train)\n",
    "y_pred = final_model.predict(X_test)\n",
    "y_train_pred=final_model.predict(X_train)\n",
    "\n",
    "y_pred = np.clip(y_pred, -1, 1)\n",
    "y_train_pred== np.clip(y_train_pred, -1, 1)\n",
    "\n",
    "model_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "model_r2 = r2_score(y_test, y_pred)\n",
    "print('r2', model_r2)\n",
    "print('RMSE', model_rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uSw6d-eulhbB",
   "metadata": {
    "id": "uSw6d-eulhbB"
   },
   "outputs": [],
   "source": [
    "predict_SWB= np.concatenate((y_train_pred, y_pred), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PyVrFgxclhdR",
   "metadata": {
    "id": "PyVrFgxclhdR"
   },
   "outputs": [],
   "source": [
    "basetable['predict_SWB']=predict_SWB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kHmlFdnpmqYJ",
   "metadata": {
    "id": "kHmlFdnpmqYJ"
   },
   "outputs": [],
   "source": [
    "basetable['created_at'] = pd.to_datetime(basetable['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4O3vMBcqmqbR",
   "metadata": {
    "id": "4O3vMBcqmqbR"
   },
   "outputs": [],
   "source": [
    "# Group by month and calculate the mean of 'Negative_affect', 'predict_neg', and 'neg'\n",
    "mean_SWB = basetable.resample('M', on='created_at')['SWB'].mean()\n",
    "mean_predict_SWB = basetable.resample('M', on='created_at')['predict_SWB'].mean()\n",
    "mean_vader_compound = basetable.resample('M', on='created_at')['compound'].mean()\n",
    "mean_textblob_score = basetable.resample('M', on='created_at')['TextBlob_score'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f906b6-a528-49db-acc3-3e9e71a2310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_predict_SWB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hsvv2XAlmqkF",
   "metadata": {
    "id": "hsvv2XAlmqkF"
   },
   "outputs": [],
   "source": [
    "end_date = pd.to_datetime('2020-02-29')\n",
    "first_months_data = basetable[basetable['created_at'] <= end_date]\n",
    "# Calculate the mean for the desired columns\n",
    "first_months_mean_SWB = first_months_data['SWB'].mean()\n",
    "first_months_mean_predict_SWB = first_months_data['predict_SWB'].mean()\n",
    "first_months_mean_vader_compound = first_months_data['compound'].mean()\n",
    "first_months_mean_textblob_score = first_months_data['TextBlob_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C_sWpaFDmqmL",
   "metadata": {
    "id": "C_sWpaFDmqmL"
   },
   "outputs": [],
   "source": [
    "#scaling\n",
    "mean_SWB=mean_SWB/np.abs(first_months_mean_SWB)\n",
    "mean_predict_SWB=mean_predict_SWB/np.abs(first_months_mean_predict_SWB)\n",
    "mean_vader_compound=mean_vader_compound/np.abs(first_months_mean_vader_compound)\n",
    "mean_textblob_score=mean_textblob_score/np.abs(first_months_mean_textblob_score)\n",
    "\n",
    "\n",
    "mean_SWB=mean_SWB[1:]\n",
    "mean_predict_SWB=mean_predict_SWB[1:]\n",
    "mean_vader_compound=mean_vader_compound[1:]\n",
    "mean_textblob_score=mean_textblob_score[1:]\n",
    "\n",
    "mean_SWB[0]=1\n",
    "mean_predict_SWB[0]=1\n",
    "mean_vader_compound[0]=1\n",
    "mean_textblob_score[0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57cc763-4677-4911-a208-fd04837fb4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')  # Resetting to default style\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "# Plot all three variables on the same plot\n",
    "mean_SWB.plot(label='Total SWB', linewidth=2.5,legend=False)\n",
    "mean_predict_SWB.plot(label='Predicted total SWB',linewidth=2.5, legend=True)\n",
    "mean_vader_compound.plot(label='VADER compound', linewidth=2.5,legend=True)\n",
    "mean_textblob_score.plot(label='TextBlob', linewidth=2.5,legend=True)\n",
    "ax.tick_params(axis='both',labelsize=16)\n",
    "\n",
    "\n",
    "# Add a vertical line at January 2021\n",
    "plt.axvline(pd.to_datetime('2021-01-01'), color='black', linestyle='--')\n",
    "ax.annotate('Training period', xy=(0.25, 0.4), fontsize=16, color='blue',xycoords='figure fraction')\n",
    "ax.annotate('Deployment period', xy=(0.7, 0.4), fontsize=16, color='blue',xycoords='figure fraction')\n",
    "\n",
    "# Add a grid\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Customize labels and title\n",
    "ax.set_xlabel('')\n",
    "ax.tick_params(labelsize=16)\n",
    "\n",
    "plt.ylabel('Values',fontsize=16)\n",
    "\n",
    "#plt.title('Mean Negative Affect, Mean Predicted Negative Affect, and Mean VADER Negative Over Months', fontsize=12)\n",
    "\n",
    "# Add a legend with a border\n",
    "#ax.legend(loc='upper left', frameon=False, framealpha=0.5)\n",
    "\n",
    "# Rotate x-axis labels for readability\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(0.2, 1), fontsize='large')\n",
    "\n",
    "# Tighten layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.savefig('TrackSWBScale.png')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
